{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e912006",
   "metadata": {},
   "source": [
    "Building a basic agent \n",
    "\n",
    "creating a simple agent that can answer questions and call tools. The agent will use Claude Sonnet 4.5 as its language model, a basic weather function as a tool, and a simple prompt to guide its behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28536d",
   "metadata": {},
   "source": [
    "Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39726ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1533705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is Paris.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model initialization\n",
    "model = init_chat_model(\"gpt-4o-mini\")\n",
    "response = model.invoke(\"What is the capital of France?\")\n",
    "response.content  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dba305",
   "metadata": {},
   "source": [
    "Creating a simple reflection agent : An agent that generates an answer and then improves on that answer through a self critique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1940f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! In simple terms:\n",
      "\n",
      "A **transformer** is a type of computer program used in artificial intelligence, especially for understanding and generating language (like how ChatGPT works).\n",
      "\n",
      "- **How it works:** Imagine you’re reading a sentence. A transformer looks at all the words in that sentence at the same time, figuring out how each word relates to the others. It uses something called **\"attention\"** to focus on the important words when making sense or coming up with a response.\n",
      "- **Why it’s special:** Older programs would read sentences word by word, but transformers can look at everything at once, which helps them understand context much better.\n",
      "\n",
      "So, transformers help computers understand language more like humans do, by paying attention to all the important parts of what’s being said.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LLMs\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0.7)\n",
    "reflect_model = ChatOpenAI(model=\"gpt-4.1\", temperature=0.2)\n",
    "\n",
    "# Nodes\n",
    "def answer_node(state):\n",
    "    question = state[\"question\"]\n",
    "    answer = model.invoke(f\"Answer this question:\\n{question}\")\n",
    "    return {\"draft_answer\": answer.content}\n",
    "\n",
    "def reflection_node(state):\n",
    "    draft = state[\"draft_answer\"]\n",
    "    critique = reflect_model.invoke(\n",
    "        f\"You are a critical reviewer. Critique the answer below. \"\n",
    "        f\"Say 'APPROVE' if good, otherwise suggest improvements.\\n\\nAnswer:\\n{draft}\"\n",
    "    ).content\n",
    "    return {\"critique\": critique}\n",
    "\n",
    "def revise_node(state):\n",
    "    draft = state[\"draft_answer\"]\n",
    "    critique = state[\"critique\"]\n",
    "    improved = model.invoke(\n",
    "        f\"Improve the answer using the critique.\\n\\nDraft:\\n{draft}\\n\\nCritique:\\n{critique}\"\n",
    "    ).content\n",
    "    return {\"draft_answer\": improved}\n",
    "\n",
    "\n",
    "# State\n",
    "class AgentState(dict):\n",
    "    question: str\n",
    "    draft_answer: str\n",
    "    critique: str\n",
    "\n",
    "# Graph\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"answer\", answer_node)\n",
    "graph.add_node(\"reflect\", reflection_node)\n",
    "graph.add_node(\"revise\", revise_node)\n",
    "\n",
    "graph.set_entry_point(\"answer\")\n",
    "graph.add_edge(\"answer\", \"reflect\")\n",
    "\n",
    "def should_revise(state):\n",
    "    return \"APPROVE\" not in state[\"critique\"].upper()\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"reflect\",\n",
    "    should_revise,\n",
    "    {\n",
    "        True: \"revise\",\n",
    "        False: END\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"revise\", \"reflect\")\n",
    "\n",
    "# ✅ Use a checkpointer\n",
    "memory = MemorySaver()\n",
    "agent = graph.compile(checkpointer=memory)\n",
    "\n",
    "# ✅ Now you can invoke\n",
    "result = agent.invoke(\n",
    "    {\"question\": \"Explain transformers in simple terms.\"},\n",
    "    config={\"thread_id\": \"run-1\"}\n",
    ")\n",
    "\n",
    "print(result[\"draft_answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
